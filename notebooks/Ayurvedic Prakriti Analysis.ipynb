{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296f39f7-902c-46f4-80f6-2f24f07f77ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in d:\\d\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\d\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\d\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\d\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\d\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in d:\\d\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\d\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\d\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\d\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\d\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\d\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in d:\\d\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in d:\\d\\lib\\site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in d:\\d\\lib\\site-packages (from seaborn) (2.3.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in d:\\d\\lib\\site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\d\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\d\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\d\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\d\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\d\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\d\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\d\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\d\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\d\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\d\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\d\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\d\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in d:\\d\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in d:\\d\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\d\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\d\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pandas in d:\\d\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\d\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\d\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\d\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\d\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\d\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in d:\\d\\lib\\site-packages (2.2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn  \n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce6e53c9-8d9e-47f7-8fa1-a7f2a2a56d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïâ  PRAKRITI DOSHA DETECTION SYSTEM üïâÔ∏è\n",
      "==================================================\n",
      "\n",
      " STEP 1: Loading Dataset\n",
      "------------------------------\n",
      "Found dataset: ./extracted_data/Prakriti.csv\n",
      "‚úì Dataset loaded successfully with utf-8 encoding!\n",
      "Dataset shape: (1200, 21)\n",
      "Columns: ['Body Size', 'Body Weight', 'Height', 'Bone Structure', 'Complexion', 'General feel of skin', 'Texture of Skin', 'Hair Color', 'Appearance of Hair', 'Shape of face', 'Eyes', 'Eyelashes', 'Blinking of Eyes', 'Cheeks', 'Nose', 'Teeth and gums', 'Lips', 'Nails', 'Appetite', 'Liking tastes', 'Dosha']\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Body Size             1200 non-null   object\n",
      " 1   Body Weight           1200 non-null   object\n",
      " 2   Height                1200 non-null   object\n",
      " 3   Bone Structure        1200 non-null   object\n",
      " 4   Complexion            1200 non-null   object\n",
      " 5   General feel of skin  1200 non-null   object\n",
      " 6   Texture of Skin       1200 non-null   object\n",
      " 7   Hair Color            1200 non-null   object\n",
      " 8   Appearance of Hair    1200 non-null   object\n",
      " 9   Shape of face         1200 non-null   object\n",
      " 10  Eyes                  1200 non-null   object\n",
      " 11  Eyelashes             1200 non-null   object\n",
      " 12  Blinking of Eyes      1200 non-null   object\n",
      " 13  Cheeks                1200 non-null   object\n",
      " 14  Nose                  1200 non-null   object\n",
      " 15  Teeth and gums        1200 non-null   object\n",
      " 16  Lips                  1200 non-null   object\n",
      " 17  Nails                 1200 non-null   object\n",
      " 18  Appetite              1200 non-null   object\n",
      " 19  Liking tastes         1200 non-null   object\n",
      " 20  Dosha                 1200 non-null   object\n",
      "dtypes: object(21)\n",
      "memory usage: 197.0+ KB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "  Body Size                                        Body Weight   Height  \\\n",
      "0    Medium  Moderate - no difficulties in gaining or losin...  Average   \n",
      "1    Medium  Moderate - no difficulties in gaining or losin...    Short   \n",
      "2      Slim  Moderate - no difficulties in gaining or losin...  Average   \n",
      "3      Slim  Moderate - no difficulties in gaining or losin...    Short   \n",
      "4     Large  Moderate - no difficulties in gaining or losin...    Short   \n",
      "\n",
      "                                  Bone Structure  \\\n",
      "0  Large, broad shoulders , heavy bone structure   \n",
      "1                          Medium bone structure   \n",
      "2                          Medium bone structure   \n",
      "3           Light, Small bones, prominent joints   \n",
      "4                          Medium bone structure   \n",
      "\n",
      "                     Complexion                General feel of skin  \\\n",
      "0      White, pale, tans easily  Dry and thin, cool to touch, rough   \n",
      "1     Fair-skin sunburns easily  Dry and thin, cool to touch, rough   \n",
      "2     Fair-skin sunburns easily        Smooth and warm, oily T-zone   \n",
      "3     Fair-skin sunburns easily  Dry and thin, cool to touch, rough   \n",
      "4  Dark-Complexion, tans easily        Smooth and warm, oily T-zone   \n",
      "\n",
      "           Texture of Skin                Hair Color  \\\n",
      "0  Dry, pigments and aging          Black/Brown,dull   \n",
      "1                     Oily  Red, light brown, yellow   \n",
      "2                     Oily          Black/Brown,dull   \n",
      "3                     Oily          Black/Brown,dull   \n",
      "4                     Oily          Black/Brown,dull   \n",
      "\n",
      "             Appearance of Hair        Shape of face  ...           Eyelashes  \\\n",
      "0                Straight, oily  Long, angular, thin  ...  Moderate eyelashes   \n",
      "1  Dry, black, knotted, brittle  Long, angular, thin  ...  Moderate eyelashes   \n",
      "2  Dry, black, knotted, brittle  Long, angular, thin  ...  Moderate eyelashes   \n",
      "3                Straight, oily   Large, round, full  ...    Scanty eyelashes   \n",
      "4  Dry, black, knotted, brittle  Long, angular, thin  ...    Scanty eyelashes   \n",
      "\n",
      "    Blinking of Eyes            Cheeks                          Nose  \\\n",
      "0  Moderate Blinking  Wrinkled, Sunken  Rounded, Large open nostrils   \n",
      "1  Moderate Blinking      Smooth, Flat  Rounded, Large open nostrils   \n",
      "2  Moderate Blinking      Smooth, Flat  Rounded, Large open nostrils   \n",
      "3  Moderate Blinking      Smooth, Flat               Crooked, Narrow   \n",
      "4  Moderate Blinking  Wrinkled, Sunken              Pointed, Average   \n",
      "\n",
      "                           Teeth and gums  \\\n",
      "0  Big, White, Strong teeth, Healthy gums   \n",
      "1        Medium-sized teeth, Reddish gums   \n",
      "2        Medium-sized teeth, Reddish gums   \n",
      "3        Medium-sized teeth, Reddish gums   \n",
      "4        Medium-sized teeth, Reddish gums   \n",
      "\n",
      "                                       Lips                            Nails  \\\n",
      "0  Tight, thin, dry lips which chaps easily    Thick, Oily, Smooth, Polished   \n",
      "1  Tight, thin, dry lips which chaps easily       Dry, Rough, Brittle, Break   \n",
      "2               Lips are soft, medium-sized  Sharp, Flexible, Pink, Lustrous   \n",
      "3               Lips are soft, medium-sized       Dry, Rough, Brittle, Break   \n",
      "4               Lips are soft, medium-sized  Sharp, Flexible, Pink, Lustrous   \n",
      "\n",
      "             Appetite                Liking tastes       Dosha  \n",
      "0     Slow but steady         Sweet / Sour / Salty  vata+pitta  \n",
      "1     Slow but steady         Sweet / Sour / Salty  vata+pitta  \n",
      "2     Slow but steady         Sweet / Sour / Salty       Pitta  \n",
      "3     Slow but steady         Sweet / Sour / Salty  vata+pitta  \n",
      "4  Strong, Unbearable  Sweet / Bitter / Astringent  vata+pitta  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Missing values:\n",
      "No missing values found!\n",
      "\n",
      "Unique values per column (first 10):\n",
      "Body Size: ['Medium' 'Slim' 'Large']\n",
      "Body Weight: ['Moderate - no difficulties in gaining or losing weight'\n",
      " 'Low - difficulties in gaining weight'\n",
      " 'Heavy - difficulties in losing weight']\n",
      "Height: ['Average' 'Short' 'Tall']\n",
      "Bone Structure: ['Large, broad shoulders , heavy bone structure' 'Medium bone structure'\n",
      " 'Light, Small bones, prominent joints']\n",
      "Complexion: ['White, pale, tans easily' 'Fair-skin sunburns easily'\n",
      " 'Dark-Complexion, tans easily']\n",
      "General feel of skin: ['Dry and thin, cool to touch, rough' 'Smooth and warm, oily T-zone'\n",
      " 'Thick and moist/greasy, cold']\n",
      "Texture of Skin: ['Dry, pigments and aging' 'Oily'\n",
      " 'Freckles, many moles, redness and rashes']\n",
      "Hair Color: ['Black/Brown,dull' 'Red, light brown, yellow' 'Brown']\n",
      "Appearance of Hair: ['Straight, oily' 'Dry, black, knotted, brittle' 'Thick, curly']\n",
      "Shape of face: ['Long, angular, thin' 'Large, round, full' 'Heart-shaped, pointed chin']\n",
      "Eyes: ['Medium-sized, penetrating, light-sensitive eyes'\n",
      " 'Small, active, darting, dark eyes' 'Big, round, beautiful, glowing eyes']\n",
      "Eyelashes: ['Moderate eyelashes' 'Scanty eyelashes' 'Thick/Fused eyelashes']\n",
      "Blinking of Eyes: ['Moderate Blinking' 'Excessive Blinking' 'More or less stable']\n",
      "Cheeks: ['Wrinkled, Sunken' 'Smooth, Flat' 'Rounded, Plump']\n",
      "Nose: ['Rounded, Large open nostrils' 'Crooked, Narrow' 'Pointed, Average']\n",
      "Teeth and gums: ['Big, White, Strong teeth, Healthy gums'\n",
      " 'Medium-sized teeth, Reddish gums'\n",
      " 'Irregular, Protruding teeth, Receding gums']\n",
      "Lips: ['Tight, thin, dry lips which chaps easily' 'Lips are soft, medium-sized'\n",
      " 'Lips are large, soft, pink, and full']\n",
      "Nails: ['Thick, Oily, Smooth, Polished' 'Dry, Rough, Brittle, Break'\n",
      " 'Sharp, Flexible, Pink, Lustrous']\n",
      "Appetite: ['Slow but steady' 'Strong, Unbearable' 'Irregular, Scanty']\n",
      "Liking tastes: ['Sweet / Sour / Salty' 'Sweet / Bitter / Astringent'\n",
      " 'Pungent / Bitter / Astringent']\n",
      "Dosha: ['vata+pitta' 'Pitta' 'Kapha' 'Vata' 'pitta+kapha' 'vata+kapha']\n",
      "\n",
      " STEP 2: Preparing Data\n",
      "------------------------------\n",
      "Auto-detected target column: 'Dosha'\n",
      "‚úì Data prepared successfully!\n",
      "Training set size: 960\n",
      "Testing set size: 240\n",
      "Number of features: 20\n",
      "Target classes: ['Kapha' 'Pitta' 'Vata' 'pitta+kapha' 'vata+kapha' 'vata+pitta']\n",
      "\n",
      " STEP 3: Training Models\n",
      "------------------------------\n",
      "Training Decision Tree model...\n",
      "‚úì Decision Tree trained!\n",
      "  Training Accuracy: 1.0000\n",
      "  Testing Accuracy: 1.0000\n",
      "Training Random Forest model...\n",
      "‚úì Random Forest trained!\n",
      "  Training Accuracy: 1.0000\n",
      "  Testing Accuracy: 1.0000\n",
      "\n",
      "üìä STEP 4: Evaluating Models\n",
      "------------------------------\n",
      "============================================================\n",
      "                MODEL EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      " DECISION TREE RESULTS:\n",
      "----------------------------------------\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Kapha       1.00      1.00      1.00        14\n",
      "       Pitta       1.00      1.00      1.00        29\n",
      "        Vata       1.00      1.00      1.00        53\n",
      " pitta+kapha       1.00      1.00      1.00        10\n",
      "  vata+kapha       1.00      1.00      1.00         9\n",
      "  vata+pitta       1.00      1.00      1.00       125\n",
      "\n",
      "    accuracy                           1.00       240\n",
      "   macro avg       1.00      1.00      1.00       240\n",
      "weighted avg       1.00      1.00      1.00       240\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 14   0   0   0   0   0]\n",
      " [  0  29   0   0   0   0]\n",
      " [  0   0  53   0   0   0]\n",
      " [  0   0   0  10   0   0]\n",
      " [  0   0   0   0   9   0]\n",
      " [  0   0   0   0   0 125]]\n",
      "\n",
      " RANDOM FOREST RESULTS:\n",
      "----------------------------------------\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Kapha       1.00      1.00      1.00        14\n",
      "       Pitta       1.00      1.00      1.00        29\n",
      "        Vata       1.00      1.00      1.00        53\n",
      " pitta+kapha       1.00      1.00      1.00        10\n",
      "  vata+kapha       1.00      1.00      1.00         9\n",
      "  vata+pitta       1.00      1.00      1.00       125\n",
      "\n",
      "    accuracy                           1.00       240\n",
      "   macro avg       1.00      1.00      1.00       240\n",
      "weighted avg       1.00      1.00      1.00       240\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 14   0   0   0   0   0]\n",
      " [  0  29   0   0   0   0]\n",
      " [  0   0  53   0   0   0]\n",
      " [  0   0   0  10   0   0]\n",
      " [  0   0   0   0   9   0]\n",
      " [  0   0   0   0   0 125]]\n",
      "\n",
      " CROSS-VALIDATION SCORES:\n",
      "----------------------------------------\n",
      "Decision Tree CV: 1.0000 (+/- 0.0000)\n",
      "Random Forest CV: 1.0000 (+/- 0.0000)\n",
      "\n",
      " WINNER: Decision Tree\n",
      "Accuracy difference: 0.0000\n",
      "\n",
      " FEATURE IMPORTANCE:\n",
      "==================================================\n",
      "\n",
      " Decision Tree - Top 10 Important Features:\n",
      " 1. Body Weight          : 0.1393\n",
      " 2. Complexion           : 0.1306\n",
      " 3. Nails                : 0.1061\n",
      " 4. Appetite             : 0.0945\n",
      " 5. Cheeks               : 0.0708\n",
      " 6. Body Size            : 0.0694\n",
      " 7. Teeth and gums       : 0.0578\n",
      " 8. Bone Structure       : 0.0538\n",
      " 9. Texture of Skin      : 0.0438\n",
      "10. General feel of skin : 0.0438\n",
      "\n",
      " Random Forest - Top 10 Important Features:\n",
      " 1. Body Weight          : 0.0777\n",
      " 2. Appetite             : 0.0687\n",
      " 3. Bone Structure       : 0.0666\n",
      " 4. Cheeks               : 0.0635\n",
      " 5. Body Size            : 0.0623\n",
      " 6. Lips                 : 0.0603\n",
      " 7. Teeth and gums       : 0.0586\n",
      " 8. Complexion           : 0.0557\n",
      " 9. Appearance of Hair   : 0.0556\n",
      "10. Eyes                 : 0.0545\n",
      "\n",
      " STEP 5: Example Prediction\n",
      "------------------------------\n",
      "Model is ready for predictions!\n",
      "Use dosha_model.predict_dosha(sample_data) to make predictions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PrakritiDoshaModel:\n",
    "    def __init__(self):\n",
    "        self.dt_model = None\n",
    "        self.rf_model = None\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_names = None\n",
    "        self.target_names = None\n",
    "        \n",
    "    def load_and_preprocess_data(self, file_path):\n",
    "        \"\"\"Load and preprocess the prakriti dosha dataset\"\"\"\n",
    "        try:\n",
    "            # Try different encodings for CSV loading\n",
    "            encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']\n",
    "            \n",
    "            for encoding in encodings:\n",
    "                try:\n",
    "                    self.data = pd.read_csv(file_path, encoding=encoding)\n",
    "                    print(f\"‚úì Dataset loaded successfully with {encoding} encoding!\")\n",
    "                    break\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "            else:\n",
    "                print(\"Could not load file with any encoding\")\n",
    "                return None\n",
    "            \n",
    "            print(f\"Dataset shape: {self.data.shape}\")\n",
    "            print(f\"Columns: {list(self.data.columns)}\")\n",
    "            \n",
    "            print(\"\\nDataset Info:\")\n",
    "            print(self.data.info())\n",
    "            \n",
    "            print(\"\\nFirst few rows:\")\n",
    "            print(self.data.head())\n",
    "            \n",
    "            print(\"\\nMissing values:\")\n",
    "            missing = self.data.isnull().sum()\n",
    "            if missing.sum() > 0:\n",
    "                print(missing[missing > 0])\n",
    "            else:\n",
    "                print(\"No missing values found!\")\n",
    "            \n",
    "            # Display unique values for each column (first 10)\n",
    "            print(\"\\nUnique values per column (first 10):\")\n",
    "            for col in self.data.columns:\n",
    "                unique_vals = self.data[col].unique()\n",
    "                print(f\"{col}: {unique_vals[:10]}\")\n",
    "            \n",
    "            return self.data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dataset: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def encode_categorical_features(self, X, y=None, fit=True):\n",
    "        \"\"\"Encode categorical features using LabelEncoder\"\"\"\n",
    "        X_encoded = X.copy()\n",
    "        \n",
    "        for column in X_encoded.columns:\n",
    "            if X_encoded[column].dtype == 'object':\n",
    "                if fit:\n",
    "                    self.label_encoders[column] = LabelEncoder()\n",
    "                    X_encoded[column] = self.label_encoders[column].fit_transform(X_encoded[column].astype(str))\n",
    "                else:\n",
    "                    if column in self.label_encoders:\n",
    "                        X_encoded[column] = self.label_encoders[column].transform(X_encoded[column].astype(str))\n",
    "        \n",
    "        if y is not None and fit:\n",
    "            if y.dtype == 'object':\n",
    "                self.target_encoder = LabelEncoder()\n",
    "                y_encoded = self.target_encoder.fit_transform(y.astype(str))\n",
    "                self.target_names = self.target_encoder.classes_\n",
    "                return X_encoded, y_encoded\n",
    "            return X_encoded, y\n",
    "        \n",
    "        return X_encoded\n",
    "    \n",
    "    def prepare_data(self, target_column, test_size=0.2, random_state=42):\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"Please load dataset first!\")\n",
    "            return None\n",
    "        \n",
    "        # Check if target column exists\n",
    "        if target_column not in self.data.columns:\n",
    "            print(f\"Target column '{target_column}' not found!\")\n",
    "            print(f\"Available columns: {list(self.data.columns)}\")\n",
    "            return None\n",
    "        \n",
    "        X = self.data.drop(columns=[target_column])\n",
    "        y = self.data[target_column]\n",
    "        \n",
    "        self.feature_names = list(X.columns)\n",
    "        \n",
    "        X_encoded, y_encoded = self.encode_categorical_features(X, y, fit=True)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X_encoded, y_encoded, test_size=test_size, random_state=random_state, stratify=y_encoded\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Data prepared successfully!\")\n",
    "        print(f\"Training set size: {self.X_train.shape[0]}\")\n",
    "        print(f\"Testing set size: {self.X_test.shape[0]}\")\n",
    "        print(f\"Number of features: {self.X_train.shape[1]}\")\n",
    "        \n",
    "        if hasattr(self, 'target_names'):\n",
    "            print(f\"Target classes: {self.target_names}\")\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def train_decision_tree(self, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        \"\"\"Train Decision Tree model\"\"\"\n",
    "        print(\"Training Decision Tree model...\")\n",
    "        \n",
    "        self.dt_model = DecisionTreeClassifier(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        self.dt_model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        dt_train_pred = self.dt_model.predict(self.X_train)\n",
    "        dt_test_pred = self.dt_model.predict(self.X_test)\n",
    "        \n",
    "        dt_train_acc = accuracy_score(self.y_train, dt_train_pred)\n",
    "        dt_test_acc = accuracy_score(self.y_test, dt_test_pred)\n",
    "        \n",
    "        print(f\"‚úì Decision Tree trained!\")\n",
    "        print(f\"  Training Accuracy: {dt_train_acc:.4f}\")\n",
    "        print(f\"  Testing Accuracy: {dt_test_acc:.4f}\")\n",
    "        \n",
    "        return self.dt_model\n",
    "    \n",
    "    def train_random_forest(self, n_estimators=100, max_depth=None, min_samples_split=2):\n",
    "        \"\"\"Train Random Forest model\"\"\"\n",
    "        print(\"Training Random Forest model...\")\n",
    "        \n",
    "        self.rf_model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        self.rf_model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        rf_train_pred = self.rf_model.predict(self.X_train)\n",
    "        rf_test_pred = self.rf_model.predict(self.X_test)\n",
    "        \n",
    "        rf_train_acc = accuracy_score(self.y_train, rf_train_pred)\n",
    "        rf_test_acc = accuracy_score(self.y_test, rf_test_pred)\n",
    "        \n",
    "        print(f\"‚úì Random Forest trained!\")\n",
    "        print(f\"  Training Accuracy: {rf_train_acc:.4f}\")\n",
    "        print(f\"  Testing Accuracy: {rf_test_acc:.4f}\")\n",
    "        \n",
    "        return self.rf_model\n",
    "    \n",
    "    def evaluate_models(self):\n",
    "        \"\"\"Evaluate both models and display results\"\"\"\n",
    "        if self.dt_model is None or self.rf_model is None:\n",
    "            print(\"Please train both models first!\")\n",
    "            return\n",
    "        \n",
    "        dt_pred = self.dt_model.predict(self.X_test)\n",
    "        rf_pred = self.rf_model.predict(self.X_test)\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"                MODEL EVALUATION RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Decision Tree Results\n",
    "        print(\"\\n DECISION TREE RESULTS:\")\n",
    "        print(\"-\" * 40)\n",
    "        dt_acc = accuracy_score(self.y_test, dt_pred)\n",
    "        print(f\"Accuracy: {dt_acc:.4f}\")\n",
    "        \n",
    "        print(\"\\nClassification Report:\")\n",
    "        if hasattr(self, 'target_names'):\n",
    "            print(classification_report(self.y_test, dt_pred, target_names=self.target_names))\n",
    "        else:\n",
    "            print(classification_report(self.y_test, dt_pred))\n",
    "        \n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        dt_cm = confusion_matrix(self.y_test, dt_pred)\n",
    "        print(dt_cm)\n",
    "        \n",
    "        # Random Forest Results\n",
    "        print(\"\\n RANDOM FOREST RESULTS:\")\n",
    "        print(\"-\" * 40)\n",
    "        rf_acc = accuracy_score(self.y_test, rf_pred)\n",
    "        print(f\"Accuracy: {rf_acc:.4f}\")\n",
    "        \n",
    "        print(\"\\nClassification Report:\")\n",
    "        if hasattr(self, 'target_names'):\n",
    "            print(classification_report(self.y_test, rf_pred, target_names=self.target_names))\n",
    "        else:\n",
    "            print(classification_report(self.y_test, rf_pred))\n",
    "        \n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        rf_cm = confusion_matrix(self.y_test, rf_pred)\n",
    "        print(rf_cm)\n",
    "        \n",
    "        # Cross-validation scores\n",
    "        print(\"\\n CROSS-VALIDATION SCORES:\")\n",
    "        print(\"-\" * 40)\n",
    "        try:\n",
    "            dt_cv_scores = cross_val_score(self.dt_model, self.X_train, self.y_train, cv=5)\n",
    "            rf_cv_scores = cross_val_score(self.rf_model, self.X_train, self.y_train, cv=5)\n",
    "            \n",
    "            print(f\"Decision Tree CV: {dt_cv_scores.mean():.4f} (+/- {dt_cv_scores.std() * 2:.4f})\")\n",
    "            print(f\"Random Forest CV: {rf_cv_scores.mean():.4f} (+/- {rf_cv_scores.std() * 2:.4f})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Cross-validation error: {e}\")\n",
    "        \n",
    "        # Model comparison\n",
    "        print(f\"\\n WINNER: {'Random Forest' if rf_acc > dt_acc else 'Decision Tree'}\")\n",
    "        print(f\"Accuracy difference: {abs(rf_acc - dt_acc):.4f}\")\n",
    "    \n",
    "    def show_feature_importance(self):\n",
    "        \"\"\"Display feature importance in text format\"\"\"\n",
    "        if self.dt_model is None or self.rf_model is None:\n",
    "            print(\"Please train both models first!\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n FEATURE IMPORTANCE:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Decision Tree\n",
    "        print(\"\\n Decision Tree - Top 10 Important Features:\")\n",
    "        dt_importance = self.dt_model.feature_importances_\n",
    "        dt_features = [(self.feature_names[i], dt_importance[i]) for i in range(len(dt_importance))]\n",
    "        dt_features.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for i, (feature, importance) in enumerate(dt_features[:10]):\n",
    "            print(f\"{i+1:2d}. {feature:<20} : {importance:.4f}\")\n",
    "        \n",
    "        # Random Forest\n",
    "        print(\"\\n Random Forest - Top 10 Important Features:\")\n",
    "        rf_importance = self.rf_model.feature_importances_\n",
    "        rf_features = [(self.feature_names[i], rf_importance[i]) for i in range(len(rf_importance))]\n",
    "        rf_features.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for i, (feature, importance) in enumerate(rf_features[:10]):\n",
    "            print(f\"{i+1:2d}. {feature:<20} : {importance:.4f}\")\n",
    "    \n",
    "    def predict_dosha(self, input_data, model_type='rf'):\n",
    "        \"\"\"Predict dosha for new input data\"\"\"\n",
    "        if model_type == 'dt' and self.dt_model is None:\n",
    "            print(\"Decision Tree model not trained!\")\n",
    "            return None\n",
    "        elif model_type == 'rf' and self.rf_model is None:\n",
    "            print(\"Random Forest model not trained!\")\n",
    "            return None\n",
    "        \n",
    "        if isinstance(input_data, dict):\n",
    "            input_df = pd.DataFrame([input_data])\n",
    "        else:\n",
    "            input_df = input_data.copy()\n",
    "        \n",
    "        input_encoded = self.encode_categorical_features(input_df, fit=False)\n",
    "        \n",
    "        if model_type == 'dt':\n",
    "            prediction = self.dt_model.predict(input_encoded)\n",
    "            probability = self.dt_model.predict_proba(input_encoded)\n",
    "        else:\n",
    "            prediction = self.rf_model.predict(input_encoded)\n",
    "            probability = self.rf_model.predict_proba(input_encoded)\n",
    "        \n",
    "        if hasattr(self, 'target_encoder'):\n",
    "            prediction_label = self.target_encoder.inverse_transform(prediction)\n",
    "        else:\n",
    "            prediction_label = prediction\n",
    "        \n",
    "        return prediction_label, probability\n",
    "\n",
    "def main_workflow():\n",
    "    \"\"\"Complete workflow for Prakriti Dosha detection\"\"\"\n",
    "    print(\"üïâ  PRAKRITI DOSHA DETECTION SYSTEM üïâÔ∏è\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Initialize model\n",
    "    dosha_model = PrakritiDoshaModel()\n",
    "    \n",
    "    # Step 1: Load dataset\n",
    "    print(\"\\n STEP 1: Loading Dataset\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Your specific dataset paths\n",
    "    possible_files = [\n",
    "        'dataset_path.txt',  # From extraction\n",
    "        './extracted_data/Prakriti.csv',  # Main dataset (602 KB)\n",
    "        './extracted_data/data.csv',      # Smaller dataset (51 KB)\n",
    "        r'C:\\ProgramData\\extracted_data\\Prakriti.csv',  # If extracted to original location\n",
    "        'Prakriti.csv',  # If copied to current directory\n",
    "        'data.csv'       # Alternative file\n",
    "    ]\n",
    "    \n",
    "    dataset_path = None\n",
    "    \n",
    "    # Try to read saved path\n",
    "    if os.path.exists('dataset_path.txt'):\n",
    "        with open('dataset_path.txt', 'r') as f:\n",
    "            dataset_path = f.read().strip()\n",
    "        print(f\"Using saved path: {dataset_path}\")\n",
    "    else:\n",
    "        # Try to find CSV files\n",
    "        for path in possible_files[1:]:\n",
    "            if os.path.exists(path):\n",
    "                dataset_path = path\n",
    "                print(f\"Found dataset: {dataset_path}\")\n",
    "                break\n",
    "    \n",
    "    if not dataset_path:\n",
    "        print(\" No dataset found! Please:\")\n",
    "        print(\"1. First extract your ZIP file using the extraction code\")\n",
    "        print(\"2. The ZIP file should be at: C:\\\\ProgramData\\\\Ayurveda prakriti dosh.zip\")\n",
    "        print(\"3. It contains: Prakriti.csv (602 KB) and data.csv (51 KB)\")\n",
    "        \n",
    "        # Try to extract automatically\n",
    "        print(\"\\n Attempting to extract ZIP file automatically...\")\n",
    "        zip_path = r\"C:\\ProgramData\\Ayurveda prakriti dosh.zip\"\n",
    "        if os.path.exists(zip_path):\n",
    "            try:\n",
    "                import zipfile\n",
    "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(\"./extracted_data/\")\n",
    "                print(\" ZIP extracted successfully!\")\n",
    "                \n",
    "                # Try to find the main dataset\n",
    "                main_dataset = \"./extracted_data/Prakriti.csv\"\n",
    "                if os.path.exists(main_dataset):\n",
    "                    dataset_path = main_dataset\n",
    "                    print(f\" Found main dataset: {dataset_path}\")\n",
    "                else:\n",
    "                    alt_dataset = \"./extracted_data/data.csv\"\n",
    "                    if os.path.exists(alt_dataset):\n",
    "                        dataset_path = alt_dataset\n",
    "                        print(f\" Found alternative dataset: {dataset_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\" Extraction failed: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\" ZIP file not found at: {zip_path}\")\n",
    "            return None\n",
    "    \n",
    "    if not dataset_path:\n",
    "        print(\" Could not locate dataset file\")\n",
    "        return None\n",
    "    \n",
    "    data = dosha_model.load_and_preprocess_data(dataset_path)\n",
    "    if data is None:\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Prepare data\n",
    "    print(f\"\\n STEP 2: Preparing Data\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Auto-detect target column\n",
    "    target_column = None\n",
    "    target_keywords = ['dosha', 'prakriti', 'constitution', 'type', 'class', 'label', 'target']\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if any(keyword in col.lower() for keyword in target_keywords):\n",
    "            target_column = col\n",
    "            print(f\"Auto-detected target column: '{target_column}'\")\n",
    "            break\n",
    "    \n",
    "    if not target_column:\n",
    "        print(\"Available columns:\")\n",
    "        for i, col in enumerate(data.columns):\n",
    "            print(f\"{i+1}. {col}\")\n",
    "        choice = input(\"Enter target column name or number: \")\n",
    "        if choice.isdigit():\n",
    "            target_column = data.columns[int(choice)-1]\n",
    "        else:\n",
    "            target_column = choice\n",
    "    \n",
    "    result = dosha_model.prepare_data(target_column)\n",
    "    if result is None:\n",
    "        return None\n",
    "    \n",
    "    # Step 3: Train models\n",
    "    print(f\"\\n STEP 3: Training Models\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    dt_model = dosha_model.train_decision_tree()\n",
    "    rf_model = dosha_model.train_random_forest()\n",
    "    \n",
    "    # Step 4: Evaluate models\n",
    "    print(f\"\\nüìä STEP 4: Evaluating Models\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    dosha_model.evaluate_models()\n",
    "    \n",
    "    # Step 5: Show feature importance\n",
    "    dosha_model.show_feature_importance()\n",
    "    \n",
    "    # Step 6: Example prediction\n",
    "    print(f\"\\n STEP 5: Example Prediction\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    print(\"Model is ready for predictions!\")\n",
    "    print(\"Use dosha_model.predict_dosha(sample_data) to make predictions\")\n",
    "    \n",
    "    return dosha_model\n",
    "\n",
    "# Running the workflow\n",
    "if __name__ == \"__main__\":\n",
    "    model = main_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "117df5dd-1704-49a4-a3f4-12413339cf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING PREDICTION SYSTEM\n",
      "==============================\n",
      "Testing with sample data from training set...\n",
      "Sample values:\n",
      "  Body Size: Medium\n",
      "  Body Weight: Moderate - no difficulties in gaining or losing weight\n",
      "  Height: Average\n",
      "  Bone Structure: Large, broad shoulders , heavy bone structure\n",
      "  Complexion: White, pale, tans easily\n",
      "  ... (and more)\n",
      "\n",
      "‚úì Test successful!\n",
      "Sample prediction: vata+pitta\n",
      "Sample confidence: 100.0%\n",
      "\n",
      "The prediction system is working correctly.\n",
      "You can now use the assessment menu safely.\n"
     ]
    }
   ],
   "source": [
    "# Test function to verify everything works\n",
    "def test_prediction():\n",
    "    \"\"\"Test prediction with sample data\"\"\"\n",
    "    print(\"TESTING PREDICTION SYSTEM\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    if not hasattr(model, 'feature_names') or not hasattr(model, 'data'):\n",
    "        print(\"Error: Model data not available.\")\n",
    "        return\n",
    "    \n",
    "    # Create sample data using the first row of training data\n",
    "    sample_data = {}\n",
    "    for feature in model.feature_names:\n",
    "        # Use the first value for each feature\n",
    "        sample_data[feature] = model.data[feature].iloc[0]\n",
    "    \n",
    "    print(f\"Testing with sample data from training set...\")\n",
    "    print(f\"Sample values:\")\n",
    "    for feature, value in list(sample_data.items())[:5]:  # Show first 5\n",
    "        print(f\"  {feature}: {value}\")\n",
    "    print(\"  ... (and more)\")\n",
    "    \n",
    "    try:\n",
    "        import pandas as pd\n",
    "        sample_df = pd.DataFrame([sample_data])\n",
    "        sample_df = sample_df[model.feature_names]  # Ensure correct order\n",
    "        \n",
    "        prediction, probability = model.predict_dosha(sample_df, model_type='rf')\n",
    "        \n",
    "        print(f\"\\n‚úì Test successful!\")\n",
    "        print(f\"Sample prediction: {prediction[0]}\")\n",
    "        print(f\"Sample confidence: {probability[0].max():.1%}\")\n",
    "        \n",
    "        print(f\"\\nThe prediction system is working correctly.\")\n",
    "        print(f\"You can now use the assessment menu safely.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Test failed: {e}\")\n",
    "        print(\"There may be an issue with the model setup.\")\n",
    "\n",
    "# Run the test first\n",
    "test_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79453cb5-e94a-4598-9f65-7da28cae643c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AYURVEDIC DOSHA DETECTION SYSTEM\n",
      "==================================================\n",
      "System ready! Starting assessment...\n",
      "\n",
      "AYURVEDIC PRAKRITI (CONSTITUTION) ASSESSMENT\n",
      "==================================================\n",
      "Choose your assessment method:\n",
      "\n",
      "1. Comprehensive Assessment (All 20 characteristics) - Most Accurate\n",
      "2. Quick Assessment (Top 8 characteristics) - 5 minutes\n",
      "3. View Dataset Information\n",
      "4. Exit\n",
      "\n",
      "Our dataset analyzes:\n",
      "‚Ä¢ Physical build and structure\n",
      "‚Ä¢ Skin and complexion characteristics\n",
      "‚Ä¢ Hair features\n",
      "‚Ä¢ Facial features\n",
      "‚Ä¢ Physiological traits\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select option (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET INFORMATION\n",
      "========================================\n",
      "Total characteristics analyzed: 20\n",
      "Training samples: 1200\n",
      "\n",
      "Constitutional types identified:\n",
      "  ‚Ä¢ Kapha\n",
      "  ‚Ä¢ Pitta\n",
      "  ‚Ä¢ Vata\n",
      "  ‚Ä¢ pitta+kapha\n",
      "  ‚Ä¢ vata+kapha\n",
      "  ‚Ä¢ vata+pitta\n",
      "\n",
      "Top 10 Most Important Characteristics:\n",
      "   1. Body Weight (0.078)\n",
      "   2. Appetite (0.069)\n",
      "   3. Bone Structure (0.067)\n",
      "   4. Cheeks (0.063)\n",
      "   5. Body Size (0.062)\n",
      "   6. Lips (0.060)\n",
      "   7. Teeth and gums (0.059)\n",
      "   8. Complexion (0.056)\n",
      "   9. Appearance of Hair (0.056)\n",
      "  10. Eyes (0.054)\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE WORKING ASSESSMENT SYSTEM - FIXED VERSION\n",
    "\n",
    "def quick_top_features_assessment_fixed():\n",
    "    \"\"\"Quick assessment using only the most important features - FIXED VERSION\"\"\"\n",
    "    print(\"QUICK PRAKRITI ASSESSMENT\")\n",
    "    print(\"=\" * 30)\n",
    "    print(\"This quick assessment focuses on the most important constitutional indicators.\")\n",
    "    print(\"Missing characteristics will be filled with typical values.\")\n",
    "    print()\n",
    "    \n",
    "    if not hasattr(model, 'rf_model') or not hasattr(model, 'feature_names'):\n",
    "        print(\"Error: Model not properly trained.\")\n",
    "        return\n",
    "    \n",
    "    # Get top 8 most important features\n",
    "    feature_importance = model.rf_model.feature_importances_\n",
    "    top_indices = feature_importance.argsort()[-8:][::-1]\n",
    "    important_features = [model.feature_names[i] for i in top_indices]\n",
    "    \n",
    "    print(\"You will be asked about these key characteristics:\")\n",
    "    for i, feature in enumerate(important_features, 1):\n",
    "        print(f\"  {i}. {feature}\")\n",
    "    print()\n",
    "    \n",
    "    # Initialize user_data with ALL features in correct order\n",
    "    user_data = {}\n",
    "    \n",
    "    # First, fill all features with most common values (defaults)\n",
    "    for feature in model.feature_names:\n",
    "        most_common = model.data[feature].mode()[0]\n",
    "        user_data[feature] = most_common\n",
    "    \n",
    "    # Now ask questions for important features only\n",
    "    for q_num, feature in enumerate(important_features, 1):\n",
    "        print(f\"Question {q_num}/8: {feature}\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        unique_values = list(model.data[feature].unique())\n",
    "        \n",
    "        for i, option in enumerate(unique_values, 1):\n",
    "            clean_option = option.replace(' , ', ', ').strip()\n",
    "            if len(clean_option) > 60:  # Truncate very long options\n",
    "                clean_option = clean_option[:57] + \"...\"\n",
    "            print(f\"  {i}. {clean_option}\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(f\"\\nSelect option (1-{len(unique_values)}): \")) - 1\n",
    "                if 0 <= choice < len(unique_values):\n",
    "                    user_data[feature] = unique_values[choice]\n",
    "                    print(f\"‚úì Selected: {unique_values[choice]}\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Please enter a number between 1 and {len(unique_values)}\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid number\")\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nAssessment cancelled\")\n",
    "                return\n",
    "        print()\n",
    "    \n",
    "    # Create DataFrame with features in correct order\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        user_df = pd.DataFrame([user_data])\n",
    "        user_df = user_df[model.feature_names]\n",
    "        \n",
    "        print(\"ANALYZING YOUR RESPONSES...\")\n",
    "        print(\"=\" * 35)\n",
    "        \n",
    "        prediction, probability = model.predict_dosha(user_df, model_type='rf')\n",
    "        \n",
    "        print(\"QUICK ASSESSMENT RESULTS\")\n",
    "        print(\"=\" * 30)\n",
    "        print(f\"Likely Constitution: {prediction[0]}\")\n",
    "        print(f\"Confidence: {probability[0].max():.1%}\")\n",
    "        \n",
    "        if hasattr(model, 'target_names'):\n",
    "            print(f\"\\nConstitution Probabilities:\")\n",
    "            sorted_results = sorted(zip(model.target_names, probability[0]), key=lambda x: x[1], reverse=True)\n",
    "            for dosha_type, prob in sorted_results:\n",
    "                percentage = prob * 100\n",
    "                bar_length = int(percentage / 5)\n",
    "                bar = \"‚ñà\" * bar_length + \"‚ñë\" * (20 - bar_length)\n",
    "                print(f\"  {dosha_type:<15}: {percentage:5.1f}% {bar}\")\n",
    "        \n",
    "        confidence = probability[0].max()\n",
    "        print(f\"\\nConfidence Assessment:\")\n",
    "        if confidence > 0.7:\n",
    "            print(\"GOOD - Strong indication based on key characteristics\")\n",
    "        elif confidence > 0.5:\n",
    "            print(\"MODERATE - Reasonable indication, consider full assessment\")\n",
    "        else:\n",
    "            print(\"LOW - Mixed characteristics, full assessment recommended\")\n",
    "        \n",
    "        print(f\"\\nNote: This quick assessment used {len(important_features)} key features.\")\n",
    "        print(f\"For more accurate results, try the comprehensive assessment.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "\n",
    "def comprehensive_dosha_assessment_fixed():\n",
    "    \"\"\"Complete Ayurvedic Prakriti assessment using all features - FIXED\"\"\"\n",
    "    print(\"COMPREHENSIVE AYURVEDIC PRAKRITI ASSESSMENT\")\n",
    "    print(\"=\"*55)\n",
    "    print(\"Please answer all questions by selecting the option that best describes you.\")\n",
    "    print()\n",
    "    \n",
    "    if not hasattr(model, 'feature_names') or not hasattr(model, 'data'):\n",
    "        print(\"Error: Model data not available.\")\n",
    "        return\n",
    "    \n",
    "    user_data = {}\n",
    "    feature_names = model.feature_names\n",
    "    total_questions = len(feature_names)\n",
    "    \n",
    "    print(f\"You will answer {total_questions} questions about your physical characteristics.\\n\")\n",
    "    \n",
    "    for current_question, feature in enumerate(feature_names, 1):\n",
    "        print(f\"Question {current_question}/{total_questions}: {feature}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        unique_values = list(model.data[feature].unique())\n",
    "        \n",
    "        for i, option in enumerate(unique_values, 1):\n",
    "            clean_option = option.replace(' , ', ', ').strip()\n",
    "            print(f\"  {i}. {clean_option}\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                choice = input(f\"\\nSelect option (1-{len(unique_values)}): \").strip()\n",
    "                choice_idx = int(choice) - 1\n",
    "                \n",
    "                if 0 <= choice_idx < len(unique_values):\n",
    "                    user_data[feature] = unique_values[choice_idx]\n",
    "                    print(f\"‚úì Selected: {unique_values[choice_idx]}\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Please enter a number between 1 and {len(unique_values)}\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid number\")\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nAssessment cancelled by user\")\n",
    "                return\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Create DataFrame and make prediction\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        user_df = pd.DataFrame([user_data])\n",
    "        user_df = user_df[model.feature_names]\n",
    "        \n",
    "        print(\"ANALYZING YOUR PRAKRITI...\")\n",
    "        print(\"=\" * 35)\n",
    "        \n",
    "        prediction, probability = model.predict_dosha(user_df, model_type='rf')\n",
    "        \n",
    "        print(\"\\nYOUR AYURVEDIC PRAKRITI ASSESSMENT RESULTS\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Primary Constitution: {prediction[0]}\")\n",
    "        print(f\"Confidence Level: {probability[0].max():.1%}\")\n",
    "        \n",
    "        if hasattr(model, 'target_names'):\n",
    "            print(f\"\\nDetailed Constitution Analysis:\")\n",
    "            print(\"-\" * 35)\n",
    "            sorted_results = sorted(zip(model.target_names, probability[0]), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for dosha_type, prob in sorted_results:\n",
    "                percentage = prob * 100\n",
    "                bar_length = int(percentage / 2.5)\n",
    "                bar = \"‚ñà\" * bar_length + \"‚ñë\" * (40 - bar_length)\n",
    "                print(f\"{dosha_type:<15}: {percentage:5.1f}% {bar}\")\n",
    "        \n",
    "        print(f\"\\nNote: This is your Ayurvedic constitutional assessment.\")\n",
    "        print(f\"For personalized guidance, consult an Ayurvedic practitioner.\")  # FIXED: Added closing quote\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during assessment: {e}\")\n",
    "\n",
    "def check_dataset_info():\n",
    "    \"\"\"Display detailed dataset information\"\"\"\n",
    "    print(\"DATASET INFORMATION\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    if hasattr(model, 'feature_names') and hasattr(model, 'data'):\n",
    "        print(f\"Total characteristics analyzed: {len(model.feature_names)}\")\n",
    "        print(f\"Training samples: {model.data.shape[0]}\")\n",
    "        \n",
    "        if hasattr(model, 'target_names'):\n",
    "            print(f\"\\nConstitutional types identified:\")\n",
    "            for dosha in model.target_names:\n",
    "                print(f\"  ‚Ä¢ {dosha}\")\n",
    "        \n",
    "        print(f\"\\nTop 10 Most Important Characteristics:\")\n",
    "        if hasattr(model, 'rf_model'):\n",
    "            feature_importance = model.rf_model.feature_importances_\n",
    "            top_indices = feature_importance.argsort()[-10:][::-1]\n",
    "            for i, idx in enumerate(top_indices, 1):\n",
    "                feature_name = model.feature_names[idx]\n",
    "                importance = feature_importance[idx]\n",
    "                print(f\"  {i:2d}. {feature_name} ({importance:.3f})\")\n",
    "    else:\n",
    "        print(\"Dataset information not available\")\n",
    "\n",
    "def prakriti_assessment_menu_fixed():\n",
    "    \"\"\"Fixed main menu for Prakriti assessment\"\"\"\n",
    "    print(\"AYURVEDIC PRAKRITI (CONSTITUTION) ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Choose your assessment method:\")\n",
    "    print()\n",
    "    print(\"1. Comprehensive Assessment (All 20 characteristics) - Most Accurate\")\n",
    "    print(\"2. Quick Assessment (Top 8 characteristics) - 5 minutes\")\n",
    "    print(\"3. View Dataset Information\")\n",
    "    print(\"4. Exit\")\n",
    "    print()\n",
    "    print(\"Our dataset analyzes:\")\n",
    "    print(\"‚Ä¢ Physical build and structure\")\n",
    "    print(\"‚Ä¢ Skin and complexion characteristics\") \n",
    "    print(\"‚Ä¢ Hair features\")\n",
    "    print(\"‚Ä¢ Facial features\")\n",
    "    print(\"‚Ä¢ Physiological traits\")\n",
    "    print()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(\"Select option (1-4): \").strip()\n",
    "            \n",
    "            if choice == '1':\n",
    "                comprehensive_dosha_assessment_fixed()\n",
    "                break\n",
    "            elif choice == '2':\n",
    "                quick_top_features_assessment_fixed()\n",
    "                break\n",
    "            elif choice == '3':\n",
    "                check_dataset_info()\n",
    "                break\n",
    "            elif choice == '4':\n",
    "                print(\"Thank you for using the Ayurvedic Prakriti Assessment System!\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter 1, 2, 3, or 4\")\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "\n",
    "# Now run the assessment system\n",
    "print(\"AYURVEDIC DOSHA DETECTION SYSTEM\")\n",
    "print(\"=\" * 50)\n",
    "print(\"System ready! Starting assessment...\")\n",
    "print()\n",
    "\n",
    "prakriti_assessment_menu_fixed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
